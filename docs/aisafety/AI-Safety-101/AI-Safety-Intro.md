---
sidebar_position: 1
---

# Why AI Safety?
The pace of AI development is accelerating, and it's clear that AI systems will soon surpass human capabilities in many areas [1]. As we continue to push the boundaries of technology, ensuring the safety of these systems is paramount. Without the right precautions, we risk encountering significant challenges.

At Apart, we're devoted to exploring and addressing the fundamental issues in [AI safety](https://en.wikipedia.org/wiki/AI_safety). We work towards analyzing the most important problems in technical AI safety while fostering a global, enthusiastic and meritocratic community around this mission.

For inquiries about speaking opportunities or potential collaborations, feel free to contact us at contact@apartresearch.com.

Organizations working on AI Safety
[Course on AI Safety](https://course.mlsafety.org/)
[How AI can turn into Rogue AI](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/)
[AI Safety Research Organization](https://apartresearch.com/)
[Stanford Center for AI Safety](https://aisafety.stanford.edu/)
[AI Safety Hackathons](https://alignmentjam.com/jam/multiagent)
[Center for AI Safety](https://www.safe.ai/)
[Antropic View on AI Safety](https://www.anthropic.com/index/core-views-on-ai-safety)

Here's an interesting video:

<iframe width="560" height="315" src="https://www.youtube.com/embed/VjuQ4kL4mws" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Continue with the rest of your Markdown content...

